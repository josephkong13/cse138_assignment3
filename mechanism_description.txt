Causal dependency tracking:

    - Each replica keep track of the number of writes each replica in its own shard has done that they are aware of in a vector clock. We call this the replica's total_vc.

    - For each key, each replica keeps track of the number of writes each replica (across ALL shards) has done that the key is causally dependent on

    - Any write/read a client does includes their causal_metadata, the initial one being an empty object.
        - The causal_metadata is a vector clock of all writes from all nodes (across ALL shards) that the client is causally aware of

    - When a client writes (PUT/DELETE) a key-value pair (k, v), the replica that receives their request increments their IP in the total_vc.
        - The replica then writes the k, v into it's kvs and returns the element-wise max of their total_vc and the client's causal metadata, called last_written_vc.
            - The replica is considered to have written key k with value v at the "time" last_written_vc. 
            - last_written_vc causally depends on all other keys the replica has written (through total_vc), and anything the client has written/read
                - Incrementing our total_vc and then taking the max with causal_metadata gives us a bigger vector clock value than anything the key-value causally depends on
        - The key value pair (k, v) is stored with the last_written_vc along with the timestamp that the server received this write request.
        - If the current node cannot PUT/DELETE the sharded key, it will attempt to forward the request to the correct replica
            - This is done periodically every 5 seconds until it times out at 20s and a 500 is sent to the client
    
    - When a client reads (GET) a key (k), the replica that receives their request:
        - First compares the key k's last_written value with the client's causal_metadata (if key k exists in the kvs)
            - If k's last_written_vc isn't older (so newer/equal/concurrent) to the causal_metadata, then k's value couldn't have depended on anything the client has seen.
                - So we can return k's value, along with the element-wise max of that key's last_written_vc and the causal_metadata
                    - last_written_vc causally depends on all other keys the replica has written since the writing of key k, and anything the client has written/read
        - If the replica wasn't able to return a causally consistent value yet, it compares it's total_vc to the causal_metadata
            - If k's total_vc is equal on newer than the causal_metadata, we can return k's value since the replica is aware of every write operation the causal_metadata depended on
                - And thus has the newest version of key k that is potentially visible to the client.
        - If the replica still wasn't able to return a causally consistent value, it stalls for 20 seconds and waits to see if it can return one (receiving an update from other replicas through gossip)
            - And still, if it isn't able to return a causally consistent value, it gives up and returns 500
        - If the current node cannot GET the sharded key, it will attempt to forward the request to the correct replica
            - This is done periodically every 5 seconds until it times out at 20s and a 500 is sent to the client

Gossip:

    - Periodically (every 500 ms) and on every write, the replica broadcasts its own kvs and total_vc to all nodes sharing the same shard

    - For a replica to merge it's kvs with a kvs it receives, it compares all common keys and keep the value with the newer associated last_written_vc
        - When the last_written_vc's are concurrent, the replica uses the timestamp to break the tie, and keeps the value and last_written_vc with the later timestamp
    - The replica also takes the element-wise max of the total_vc it received and its own, since it is now aware of all writes up to that new clock value.
        - I.e. When a replica with total_vc [5, 0] receives a kvs and total_vc with [0, 5], it is aware of [5, 5] writes after merging the kvs's.

Sharding:

    - We are using consistent hashing in a 32 bit ring with 100 virtual nodes for each shard

    - When a view change is initiated for a cluster: 
        - Shard numbers are assigned to each node in a round-robin mechanism, this is stored in the state as a "view" object (the view is only generated if it is not passed to us by an initialized node)
        - Broadcast the view change to all nodes in the new view  
        - Virtual nodes are generated in the state for each shard and are sorted according to their hash number (so that they can be binary searched later on)
        - Reshard the KVS. This is done by assigning new shards to previous keys by using a binary search on our virtual nodes to find the nearest matching node. (in the case of a hash collision we pick one virtual node) 
        - Send out keys on our shard to their proper shards 
        - Delete any nodes that are no longer in our view

    - When a reshard operation is done, all vector clocks (total_vc, and last_written_vc for all keys) are reset to zero

    - Deleting a node also triggers a reshard operation that broadcasts that shard's kvs to its respective destination(s)

    - When a replica receives a request for a key, it uses its list of virtual nodes (in state) and the key's hash to determine which shard is responsible for that key
        - If the replica is in the shard responsible for the key, it procedes as normal.
        - If some other shard is responsible, it forwards the request to all nodes in that shard, returning the first response it gets back


We did not implement any mechanisms to detect whether a replica is down.